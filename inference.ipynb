{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import mean\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import math\n",
    "from model.LSnet import * \n",
    "import neptune.new as neptune\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_percentage_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write testset to .txt\n",
    "\n",
    "* FORMAT  \n",
    "육안검사, 코로나검사, 적외선검사, PD검사, 문진점수, 기준수명, 경과수명, HI, 최종수명 \n",
    "\n",
    "    ex) 100,100,75,100,30,30,20,85.19999999999999,8.52\n",
    "\n",
    "Or use utils/gendataset.py to generate test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Dataset/\", exist_ok= True)\n",
    "test_list = np.array([75,50,74,0,10,30,27,38.008,1])\n",
    "f = open(\"Dataset/inference.txt\",'w')\n",
    "# f.write(test_list)\n",
    "f.write(\",\".join(str(j) for j in test_list)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSDataset_val(Dataset):\n",
    "    def __init__(self):\n",
    "        txt ='Dataset/inference.txt'\n",
    "        self.f_ = np.loadtxt(txt, 'str', delimiter=',', skiprows=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.f_.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw = self.f_\n",
    "        data = torch.Tensor(raw[:-2].astype(\"float\"))\n",
    "        hi = torch.Tensor([raw[-2].astype(\"float\")])\n",
    "        flsp=torch.Tensor([raw[-1].astype(\"float\")])\n",
    "        return data, hi, flsp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([100., 100.,  75., 100.,  30.,  30.,  20.]), tensor([85.2000]), tensor([8.5200]))\n"
     ]
    }
   ],
   "source": [
    "test_dataset= LSDataset_val()\n",
    "test_loader = DataLoader(dataset= test_dataset, batch_size = 1, shuffle = False, num_workers=0)\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "batch_size =1\n",
    "test_dataset= LSDataset_val()\n",
    "test_loader = DataLoader(dataset= test_dataset, batch_size = 1, shuffle = False, num_workers=0)\n",
    "model = Build14(in_ch=7, out_ch=1)\n",
    "model.load_state_dict(torch.load('/mnt/e/Workspace/jm/Projects/baby_eval/output/SL1_SGD_300_0010414.pth')) # model path\n",
    "model.to(device)\n",
    "model.eval()\n",
    "criterion = [torch.nn.SmoothL1Loss(), torch.nn.SmoothL1Loss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI pred: 85.22245788574219,  HI GT: 85.19999694824219\n",
      "LS pred: 8.796286582946777, LS GT: 8.520000457763672\n",
      "mae : 0.2021484375, 2.486575126647949\n",
      "mape : 0.23726343279425513, 0.0\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for epoch in range(1):\n",
    "    iter = math.ceil(len(test_dataset)/batch_size)\n",
    "    loss_val, mae_hi, mape_hi, mae_fnls, mape_fnls =0,0,0,0,0\n",
    "    cnt+=1\n",
    "    with torch.no_grad():\n",
    "        for data, hi_gt, fnls_gt in test_loader:\n",
    "            x, y1_val, y2_val = data.to(device), hi_gt.to(device), fnls_gt.to(device)\n",
    "            y1_pred_val, y2_pred_val = model(x)                \n",
    "            val_loss_hi = criterion[0](y1_pred_val, y1_val)\n",
    "            val_loss_fnls = criterion[1](y2_pred_val, y2_val)\n",
    "            val_loss =   val_loss_hi +  val_loss_fnls\n",
    "\n",
    "            hi_pred = y1_pred_val.squeeze().cpu().numpy()\n",
    "            fnls_pred = y2_pred_val.squeeze().cpu().numpy()\n",
    "            hi_gt = y1_val.squeeze().cpu().numpy() \n",
    "            fnls_gt = y2_val.squeeze().cpu().numpy() \n",
    "\n",
    "            mae_hi += np.abs(hi_gt- hi_pred)\n",
    "            mape_hi += 100* np.abs(hi_gt-hi_pred)/hi_gt\n",
    "            mae_fnls +=  np.abs(fnls_gt- fnls_pred)\n",
    "            mape_fnls += 100* np.abs(fnls_gt-fnls_gt)/fnls_gt\n",
    "print(\"HI pred: {},  HI GT: {}\\nLS pred: {}, LS GT: {}\".format(hi_pred, hi_gt, fnls_pred, fnls_gt))\n",
    "print(\"mae : {}, {}\".format(mae_hi, mae_fnls))\n",
    "print(\"mape : {}, {}\".format(mape_hi, mape_fnls))\n",
    "\n",
    "# mae = mean_squared_error(hi_gt, hi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1de32a2c4b1234568de3f42898b5fb77cdc89d0b8685311417994c24f4e6feb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('jm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
